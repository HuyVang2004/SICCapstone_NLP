{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import ast\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, recall_score, precision_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = [\"Near\", \"Mid\", \"Far\", \"Potential\"]\n",
    "\n",
    "near_train = pd.read_csv(f\"../../data/cleaned/Title/Near_processed_train.csv\")[[\"Words\", \"origin\", \"Near\"]]\n",
    "near_test = pd.read_csv(f\"../../data/cleaned/Title/Near_processed_test.csv\")[[\"Words\", \"origin\", \"Near\"]]\n",
    "\n",
    "mid_train = pd.read_csv(f\"../../data/cleaned/Title/Mid_processed_train.csv\")[[\"Words\", \"origin\", \"Mid\"]]\n",
    "mid_test = pd.read_csv(f\"../../data/cleaned/Title/Mid_processed_test.csv\")[[\"Words\", \"origin\", \"Mid\"]]\n",
    "\n",
    "far_train = pd.read_csv(f\"../../data/cleaned/Title/Far_processed_train.csv\")[[\"Words\", \"origin\", \"Far\"]]\n",
    "far_test = pd.read_csv(f\"../../data/cleaned/Title/Far_processed_test.csv\")[[\"Words\", \"origin\", \"Far\"]]\n",
    "\n",
    "potential_train = pd.read_csv(f\"../../data/cleaned/Title/Potential_processed_train.csv\")[[\"Words\", \"origin\", \"Potential\"]]\n",
    "potential_test = pd.read_csv(f\"../../data/cleaned/Title/Potential_processed_test.csv\")[[\"Words\", \"origin\", \"Potential\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Words     False\n",
       "origin    False\n",
       "Near      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "near_test.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_vector1(doc, model):\n",
    "    vectors = [model.wv[word] for word in doc if word in model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Khai báo và các tham số tối ưu mô hình học máy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    SVC(random_state=42),\n",
    "    LogisticRegression(solver='saga', random_state=42),\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    AdaBoostClassifier(random_state=42),\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    KNeighborsClassifier(),\n",
    "    GaussianNB()\n",
    "]\n",
    "\n",
    "param_grids = [\n",
    "    {'C': [0.1, 1, 10, 100, 1000],  #SVC\n",
    "     'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "     'kernel': ['rbf', 'sigmoid']},\n",
    "    {\"penalty\":[\"l1\",\"l2\"]}, #LogisticRegression\n",
    "    {'max_features':[1,3,5,7], #RandomForestClassifier\n",
    "     'min_samples_leaf':[1,2,3],},\n",
    "    {'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0]}, #AdaBoostClassifier\n",
    "    {'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0]}, #GradientBoostingClassifier\n",
    "    {'n_neighbors': [2,3,5,7]}, #KNeighborsClassifier\n",
    "    {'var_smoothing': [0.00000001, 0.000000001, 0.00000001]} #GaussianNB\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_buildML(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    model_fast = FastText(sentences=X_train, vector_size=50, window=5, min_count=1, workers=4)\n",
    "\n",
    "    X_train = np.array([get_document_vector1(doc, model_fast) for doc in X_train])\n",
    "    X_test = np.array([get_document_vector1(doc, model_fast) for doc in X_test])\n",
    "\n",
    "    res = []\n",
    "    for i in range(len(models)):\n",
    "        grid = GridSearchCV(models[i], param_grids[i], refit = True, verbose = 0) \n",
    "        grid.fit(X_train, y_train) \n",
    "        model = grid.best_estimator_\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        result = [f\"{type(model).__name__}\", accuracy_score(y_test, y_pred),\n",
    "                precision_score(y_test, y_pred),\n",
    "                recall_score(y_test, y_pred),\n",
    "                f1_score(y_test, y_pred)]\n",
    "        res.append(result)\n",
    "    return pd.DataFrame(res, columns = [\"Model\", \"Accuracy\", \"Precision\", \"Recal\", \"F1 score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimentML_evaluate(data_train, data_test, models, param_grids):\n",
    "    origin_train_data = data_train[data_train[\"origin\"] == 0]\n",
    "    augmented_train_data = data_train[data_train[\"origin\"] == 1]\n",
    "\n",
    "    origin_test_data = data_test[data_test[\"origin\"] == 0]\n",
    "    augmented_test_data = data_test[data_test[\"origin\"] == 1]\n",
    "    \n",
    "    X_train_origin = origin_train_data[\"Words\"]\n",
    "    X_test_origin = origin_test_data[\"Words\"]\n",
    "\n",
    "    X_train_augmented = augmented_train_data[\"Words\"]\n",
    "    X_test_augmented = augmented_test_data[\"Words\"]\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y_train_origin = pd.DataFrame(le.fit_transform(origin_train_data.iloc[:, -1]))\n",
    "    y_test_origin = pd.DataFrame(le.transform(origin_test_data.iloc[:, -1]))\n",
    "\n",
    "    y_train_augmented = pd.DataFrame(le.transform(augmented_train_data.iloc[:, -1]))\n",
    "    y_test_augmented = pd.DataFrame(le.transform(augmented_test_data.iloc[:, -1]))\n",
    "\n",
    "    print(\"Basic origin - origin\")\n",
    "    res = w2v_buildML(X_train_origin, X_test_origin, y_train_origin, y_test_origin)\n",
    "    print(res)\n",
    "\n",
    "    print(\"Augmented - origin\")\n",
    "    res = w2v_buildML(pd.concat((X_train_origin, X_train_augmented), axis=0), X_test_origin, \n",
    "                      pd.concat((y_train_origin, y_train_augmented), axis=0), y_test_origin)\n",
    "    print(res)\n",
    "\n",
    "    print(\"Augmented - augmented\")\n",
    "    res = w2v_buildML(pd.concat((X_train_origin, X_train_augmented), axis=0), pd.concat((X_test_origin, X_test_augmented), axis=0), \n",
    "                      pd.concat((y_train_origin, y_train_augmented), axis=0), pd.concat((y_test_origin, y_test_augmented), axis=0))\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic origin - origin\n",
      "                        Model  Accuracy  Precision   Recal  F1 score\n",
      "0                         SVC  0.559140   0.000000  0.0000  0.000000\n",
      "1          LogisticRegression  0.569892   0.000000  0.0000  0.000000\n",
      "2      RandomForestClassifier  0.451613   0.365854  0.3750  0.370370\n",
      "3          AdaBoostClassifier  0.424731   0.416149  0.8375  0.556017\n",
      "4  GradientBoostingClassifier  0.510753   0.442105  0.5250  0.480000\n",
      "5        KNeighborsClassifier  0.516129   0.391304  0.2250  0.285714\n",
      "6                  GaussianNB  0.500000   0.417722  0.4125  0.415094\n",
      "Augmented - origin\n",
      "                        Model  Accuracy  Precision   Recal  F1 score\n",
      "0                         SVC  0.510753   0.435294  0.4625  0.448485\n",
      "1          LogisticRegression  0.559140   0.468750  0.1875  0.267857\n",
      "2      RandomForestClassifier  0.516129   0.424242  0.3500  0.383562\n",
      "3          AdaBoostClassifier  0.494624   0.400000  0.3500  0.373333\n",
      "4  GradientBoostingClassifier  0.462366   0.321429  0.2250  0.264706\n",
      "5        KNeighborsClassifier  0.521505   0.450549  0.5125  0.479532\n",
      "6                  GaussianNB  0.569892   0.500000  0.2250  0.310345\n",
      "Augmented - augmented\n",
      "                        Model  Accuracy  Precision     Recal  F1 score\n",
      "0                         SVC  0.498728   0.480000  0.442105  0.460274\n",
      "1          LogisticRegression  0.536896   0.527586  0.402632  0.456716\n",
      "2      RandomForestClassifier  0.544529   0.534591  0.447368  0.487106\n",
      "3          AdaBoostClassifier  0.488550   0.463087  0.363158  0.407080\n",
      "4  GradientBoostingClassifier  0.520356   0.504673  0.426316  0.462197\n",
      "5        KNeighborsClassifier  0.515267   0.498695  0.502632  0.500655\n",
      "6                  GaussianNB  0.530534   0.516418  0.455263  0.483916\n"
     ]
    }
   ],
   "source": [
    "sentimentML_evaluate(near_train, near_test, models, param_grids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
